{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naver_senti.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN8NOC6THxL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hugging Face의 트랜스포머 모델을 설치\n",
        "!pip install transformers\n",
        "!pip install pytorch_pretrained_bert==0.4.0\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertForSequenceClassification\n",
        "from transformers import AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "#드라이브에 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#기본 BERT모델의 tokenizer를 ETRI 한국어 버트 모델의 tokenizer으로 변경함.\n",
        "#한국어 버트 모델 다운로드를 위해서 ETRI의 승인을 받아야 합니다.\n",
        "!cp \"/content/drive/My Drive/bert_pytorch/001_bert_morp_pytorch/src_tokenizer/tokenization_morp.py\" /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/\n",
        "from pytorch_pretrained_bert.tokenization_morp import BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3RIoT7BIAQ8",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 로드 및 *전처리*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjc9t7jKIEe6",
        "colab_type": "code",
        "outputId": "628bb1b8-2497-4292-9693-d98b78261271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "# 판다스로 훈련셋 데이터 로드\n",
        "test_data = pd.read_csv(\"/content/drive/My Drive/하/test_morphs.txt\", sep='\\t',header=None)\n",
        "train_data=pd.read_csv('/content/drive/My Drive/하/train_morphs.txt', sep='\\t',header=None)\n",
        "print(train_data)\n",
        "print(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               0                                                  1  2\n",
            "0        9976970  아/IC 더/NNP 빙/NNG ../SE 진짜/MAG 짜증/NNG 나/VV 네/XS...  0\n",
            "1        3819312  흠/IC ./SF ../SE 포스터/NNG 보/VV 고/EC 초딩/NNG 영화/NN...  1\n",
            "2       10265843  너무/MAG 재/VA 밓/VV 었/EP 다/EC 그래서/MAJ 보/VV 는/ETM ...  0\n",
            "3        9045019  교도소/NNG 이야기/NNG 이/VCP 구/EF 먼/EC ../SE 솔직히/MAG ...  0\n",
            "4        6483659  사이/NNP 몬/NNG 페그/NNP 의/JKG 익살/NNG 스럽/XSA ㄴ/ETM ...  1\n",
            "...          ...                                                ... ..\n",
            "149995   6222902  인간/NNG 이/JKS 문제지/NNG ./SF ./SE 소/NNG 는/JX 뭔/MM...  0\n",
            "149996   8549745             평점/NNG 이/JKS 너무/MAG 낮/VA 아서/EC .../SE   1\n",
            "149997   9311800  이것/NP 이/JKS 뭐/NP 이/VCP 오/EF ?/SF 한국인/NNG 은/JX ...  0\n",
            "149998   2376369  청춘/NNG 영화/NNG 의/JKG 최고봉/NNG ./SP 방황/NNG 과/JKB ...  1\n",
            "149999   9619869  한국/NNP 영화/NNG 최초/NNG 로/JKB 수간/NNG 하/XSV 는/ETM ...  0\n",
            "\n",
            "[150000 rows x 3 columns]\n",
            "             0                                                  1  2\n",
            "0      6270596                                       굳/MAG ㅋ/NNG   1\n",
            "1      9274899                           GDNTOPCLASSINTHECLUB/SL   0\n",
            "2      8544678  뭐/NP 야/JX 이/NNG 평점/NNG 들/XSN 은/JX ..../SE 나쁘/V...  0\n",
            "3      6825595  지루/XR 하/XSA 지/EC 는/JX 않/VX 은데/EC 완전/NNG 막장임/NN...  0\n",
            "4      6723715  3/SN D/SL 만/JX 아니/VCN 었/EP 어도/EC 별/MM 다섯/NR 개/...  0\n",
            "...        ...                                                ... ..\n",
            "49995  4608761  오랜만/NNG 에/JKB 평점/NNG 로/JKB 이/VCP 기/ETN ㄴ/JX 하/...  1\n",
            "49996  5308387  의지/NNG 박약/NNG 들/XSN 이나/JX 하/VV 는/ETM 거/NNB 다/M...  0\n",
            "49997  9072549  그림/NNG 도/JX 좋/VA 고/EC 완성도/NNG 도/JX 높/VA 았/EP 지...  0\n",
            "49998  5802125  절대/MAG 보/VV 아서/EC 는/JX 안/MAG 되/VV ㄹ/ETM 영화/NNG...  0\n",
            "49999  6070594               마무리/NNG 는/JX 또/MAG 왜/MAG 이러/VV 어/EC   0\n",
            "\n",
            "[50000 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMT91oJxIJwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train set 리뷰 문장 추출\n",
        "sentences_train=list()\n",
        "for i in range(len(train_data[1])):\n",
        "  if(type(train_data[1][i])==float):\n",
        "    sentences_train.append(\"[CLS] [SEP]\")\n",
        "  else:\n",
        "    sentences_train.append(\"[CLS] \"+train_data[1][i]+\" [SEP]\")\n",
        "  \n",
        "#test set 리뷰 문장 추출\n",
        "sentences_test=list()\n",
        "for i in range(len(test_data[1])):\n",
        "  if(type(test_data[1][i])==float):\n",
        "    sentences_test.append(\"[CLS] [SEP]\")\n",
        "  else:\n",
        "\n",
        "    sentences_test.append(\"[CLS] \"+test_data[1][i]+\" [SEP]\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEuIf3ciXNdJ",
        "colab_type": "code",
        "outputId": "defff586-92de-433a-c2e7-b66bebb6b5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "print(sentences_train[0:9])\n",
        "print(len(sentences_train))\n",
        "print(sentences_test[0:9])\n",
        "print(len(sentences_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS] 아/IC 더/NNP 빙/NNG ../SE 진짜/MAG 짜증/NNG 나/VV 네/XSN 요목/NNG 소리/NNG  [SEP]', '[CLS] 흠/IC ./SF ../SE 포스터/NNG 보/VV 고/EC 초딩/NNG 영화/NNG 줄/NNG ./SF .../SE 오버/NNG 연기/NNG 조차/JX 가볍/VA 지/EC 않/VX 구나/EC  [SEP]', '[CLS] 너무/MAG 재/VA 밓/VV 었/EP 다/EC 그래서/MAJ 보/VV 는/ETM 것/NNB 을/JKO 추천/NNG 하/XSV ㄴ다/EC  [SEP]', '[CLS] 교도소/NNG 이야기/NNG 이/VCP 구/EF 먼/EC ../SE 솔직히/MAG 재미/NNG 는/JX 없/VA 다/EF ./SF ./SE 평점/NNG 조정/NNG  [SEP]', '[CLS] 사이/NNP 몬/NNG 페그/NNP 의/JKG 익살/NNG 스럽/XSA ㄴ/ETM 연기/NNG 가/JKS 돋보이/VV 었/EP 던/ETM 영화/NNG !/SP 스파/NNG 이더/NNP 맨/NNG 에서/JKB 늙/VV 어/EC 보이/VV 기/ETN 만/JX 하/VX 였/EP 던/ETM 커스틴/NNP 던/NNP 스트/NNG 가/JKS 너무나/MAG 도/JX 이쁘/VV 어/EC 보이/VV 었/EP 다/EC  [SEP]', '[CLS] 막걸음마/NNG 떼/VV ㄴ/ETM 3/SN 세/NNB 부터/JX 초등학교/NNG 1/SN 학년/NNG 생/XSN 이/VCP ㄴ/ETM 8/SN 살/NNB 용/NNG 영화/NNG ./SP ㅋ/IC ㅋ/NNG ㅋ/IC .../SE 별반/NNG 개/NNG 도/JX 아깝/VA ㅁ/ETN ./SF  [SEP]', '[CLS] 원작/NNG 의/JKG 긴장감/NNG 을/JKO 제대로/MAG 살리/VV 어/EC 내/VX 지/EC 못하/VX 였/EP 다/EF ./SF  [SEP]', '[CLS] 별반/MAG 개/NNG 도/JX 아깝/VA 다/EC 욕/NNG 나오/VV ㄴ/ETM 다/MAG 이/MM 응/NNG 경길용우/NNP 연기/NNG 생활/NNG 이/JKS 몇/MM 년/NNB 이/VCP ㄴ지/EF ./SP ./SE 정말/MAG 발/NNG 로/NNP 하/XSV 여도/EC 그것/NP 보다/JKB ㄴ/JX 낫겟/NNG 다/EC 납치/NNG ./SF 감금/NNG 만/JX 반복/NNG 반복/NNG ./SP ./SF 이/JKS 드라마/NNG 는/JX 가족/NNG 도/JX 없/VA 다/EC 연기/NNG 못하/VX 는/ETM 사람/NNG 만/JX 모/NNG 엿/NNP 네/NNG  [SEP]', '[CLS] 액션/NNG 이/JKS 없/VA 는데/EC 도/JX 재미있/VA 는/ETM 몇/MM 안/MAG 되/VV 는/ETM 영화/NNG  [SEP]']\n",
            "150000\n",
            "['[CLS] 굳/MAG ㅋ/NNG  [SEP]', '[CLS] GDNTOPCLASSINTHECLUB/SL  [SEP]', '[CLS] 뭐/NP 야/JX 이/NNG 평점/NNG 들/XSN 은/JX ..../SE 나쁘/VA 지/EC ㄴ/JX 않/VX 지만/EC 10/SN 점/NNB 짜리/XSN 는/JX 더더욱/MAG 아니/VCN 지/EC 않/VX 아/EC  [SEP]', '[CLS] 지루/XR 하/XSA 지/EC 는/JX 않/VX 은데/EC 완전/NNG 막장임/NNG ./SP ../SE 돈/NNG 주/VV 고/EC 보/VV 기에/EC 는/JX ..../SE  [SEP]', '[CLS] 3/SN D/SL 만/JX 아니/VCN 었/EP 어도/EC 별/MM 다섯/NR 개/NNB 주/VV 었/EP 을/ETM 터/NNB 이/VCP ㄴ데/EF ../SE 왜/MAG 3/SN D/SL 로/JKB 나오/VV 아서/EC 저/NP 의/JKG 심기/NNG 를/JKO 불편/NNG 하/XSA 게/EC 하/VX 죠/EF ??/SF  [SEP]', '[CLS] 음악/NNG 이/JKS 주가/NNG 되/VV ㄴ/ETM ,/SP 최고/NNG 의/JKG 음악/NNG 영화/NNG  [SEP]', '[CLS] 진정/XR 하/XSA ㄴ/ETM 쓰레기/NNG  [SEP]', '[CLS] 마치/MAG 미국/NNP 애니/NNG 에서/JKB 튀어나오/VV ㄴ/ETM 듯/NNB 하/XSA ㄴ/ETM 창의력/NNG 없/VA 는/ETM 로봇/NNG 디자인/NNG 부터/JX 가/JKS ,/SP 고개/NNG 를/JKO 젖/VV 게/EC 하/VX ㄴ다/EC  [SEP]', '[CLS] 갈수록/MAG 개판/NNG 되/XSV 가/EC 는/JX 중국/NNP 영화/NNG 유치/XR 하/XSA 고/EC 내용/NNG 없/VA 음/ETN 폼/NNG 잡/VV 다/EC 끝나/VV ㅁ/EC 말/NNG 도/JX 안/MAG 되/VV 는/ETM 무기/NNG 에/JKB 유치/XR 하/XSA ㄴ/ETM cg/SL 남무아/NNP 그립/VA 다/EC 동/NNG 사서독/NNP 같/VA 은/ETM 영화/NNG 가/JKS 이것/NP ㄴ/JX 3/SN 류/XSN 아류작/NNG 이/VCP 다/EC  [SEP]']\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXfaUcm1IVPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train set 라벨 추출\n",
        "labels_train = list()\n",
        "for i in range(len(train_data[2])):\n",
        "  labels_train.append(train_data[2][i])\n",
        "print(labels_train)\n",
        "print(len(labels_train))\n",
        "print(labels_train[0:9])\n",
        "\n",
        "# test set 라벨 추출\n",
        "labels_test = list()\n",
        "for i in range(len(test_data[2])):\n",
        "  labels_test.append(test_data[2][i])\n",
        "print(labels_test)\n",
        "print(len(labels_test))\n",
        "print(labels_test[0:9])\n",
        "\n",
        "\n",
        "#메모리 최적화를 위해 필요 없는 변수 삭제\n",
        "del(train_data)\n",
        "del(test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtUxckGFIgZb",
        "colab_type": "code",
        "outputId": "d15dca7d-c3e5-44e9-9122-45211ce70188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/My Drive/bert_pytorch/001_bert_morp_pytorch/vocab.korean_morp.list\", do_lower_case=False)\n",
        "tokenized_train_texts = [tokenizer.tokenize(sent) for sent in sentences_train]\n",
        "print (sentences_train[0])\n",
        "print (tokenized_train_texts[0])\n",
        "print(len(tokenized_train_texts))\n",
        "\n",
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenized_test_texts = [tokenizer.tokenize(sent) for sent in sentences_test]\n",
        "print (sentences_test[0])\n",
        "print (tokenized_test_texts[0])\n",
        "print(len(tokenized_test_texts))\n",
        "\n",
        "\n",
        "#메모리 최적화를 위해 필요 없는 변수 삭제\n",
        "del(sentences_train)\n",
        "del(sentences_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 아/IC 더/NNP 빙/NNG ../SE 진짜/MAG 짜증/NNG 나/VV 네/XSN 요목/NNG 소리/NNG  [SEP]\n",
            "['[CLS]', '_', '아/IC_', '더/NNP_', '빙/NNG_', '.', '.', '/SE_', '진', '짜', '/MAG_', '짜', '증/NNG_', '나/VV_', '네/XSN_', '요', '목/NNG_', '소리/NNG_', '[SEP]', '_']\n",
            "150000\n",
            "[CLS] 굳/MAG ㅋ/NNG  [SEP]\n",
            "['[CLS]', '_', '굳', '/MAG_', 'ㅋ', '/NNG_', '[SEP]', '_']\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNIgZ-gQdMLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#필요 없는 띄어쓰기 삭제\n",
        "_removed_tokenized_train_texts=list()\n",
        "for sent in tokenized_train_texts:\n",
        "  while('_' in sent):\n",
        "    sent.remove('_')\n",
        "  _removed_tokenized_train_texts.append(sent)\n",
        "\n",
        "#필요 없는 띄어쓰기 삭제\n",
        "_removed_tokenized_test_texts=list()\n",
        "for sent in tokenized_test_texts:\n",
        "  while('_' in sent):\n",
        "    sent.remove('_')\n",
        "  _removed_tokenized_test_texts.append(sent)\n",
        "\n",
        "\n",
        "#메모리 최적화를 위해 필요 없는 변수 삭제\n",
        "del(tokenized_train_texts)\n",
        "del(tokenized_test_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA9iDUKUdwqz",
        "colab_type": "code",
        "outputId": "50bd61b7-0cde-4599-8095-b455058b4314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "print(_removed_tokenized_train_texts[0])\n",
        "print(tokenizer.convert_tokens_to_ids(_removed_tokenized_train_texts[0]))\n",
        "print(len(_removed_tokenized_train_texts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', '아/IC_', '더/NNP_', '빙/NNG_', '.', '.', '/SE_', '진', '짜', '/MAG_', '짜', '증/NNG_', '나/VV_', '네/XSN_', '요', '목/NNG_', '소리/NNG_', '[SEP]']\n",
            "[2, 7016, 4600, 3488, 18168, 18168, 21245, 351, 3349, 228, 3349, 2315, 515, 4384, 826, 1040, 1557, 3]\n",
            "150000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFlCJ8yUVfaM",
        "colab_type": "code",
        "outputId": "1d9d21ce-3c7c-47c2-fd54-210500a8aab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(_removed_tokenized_test_texts[0])\n",
        "print(tokenizer.convert_tokens_to_ids(_removed_tokenized_test_texts[0]))\n",
        "print(len(_removed_tokenized_test_texts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', '굳', '/MAG_', 'ㅋ', '/NNG_', '[SEP]']\n",
            "[2, 6956, 228, 10494, 83, 3]\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSmAancTNJ0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 256\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_train_ids = [tokenizer.convert_tokens_to_ids(x) for x in _removed_tokenized_train_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_train_ids = pad_sequences(input_train_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 256\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_test_ids = [tokenizer.convert_tokens_to_ids(x) for x in _removed_tokenized_test_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_test_ids = pad_sequences(input_test_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "\n",
        "#필요 없는 변수 삭제\n",
        "del(_removed_tokenized_train_texts)\n",
        "del(_removed_tokenized_test_texts)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVjQ4bt_YsYi",
        "colab_type": "code",
        "outputId": "17877ecf-30c0-438e-9eac-f3485764739b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "print(input_train_ids[0])\n",
        "len(input_train_ids)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    2  7016  4600  3488 18168 18168 21245   351  3349   228  3349  2315\n",
            "   515  4384   826  1040  1557     3     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReAq6uPPWtC2",
        "colab_type": "code",
        "outputId": "77eb61e0-4f05-4faa-bd24-1b29593a0672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "print(input_test_ids[0])\n",
        "len(input_test_ids)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    2  6956   228 10494    83     3     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgI3JSXBObzM",
        "colab_type": "code",
        "outputId": "9825dc4f-a8a1-482e-9d16-cdcb25e91436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_train_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_train_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_train_masks.append(seq_mask)\n",
        "\n",
        "print(attention_train_masks[0])\n",
        "print(len(attention_train_masks))\n",
        "# 어텐션 마스크 초기화\n",
        "attention_test_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_test_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_test_masks.append(seq_mask)\n",
        "\n",
        "print(attention_test_masks[0])\n",
        "print(len(attention_test_masks))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "150000\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7NlRLrQUKC2",
        "colab_type": "code",
        "outputId": "0f0a848b-134d-46fc-8684-6f53d5c8df2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\n",
        "train_inputs = torch.tensor(input_train_ids)\n",
        "train_labels = torch.tensor(labels_train)\n",
        "train_masks = torch.tensor(attention_train_masks)\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(len(train_inputs))\n",
        "print(len(train_labels))\n",
        "print(len(train_masks))\n",
        "\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs = torch.tensor(input_test_ids)\n",
        "test_labels = torch.tensor(labels_test)\n",
        "test_masks = torch.tensor(attention_test_masks)\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(len(train_inputs))\n",
        "print(len(train_labels))\n",
        "print(len(train_masks))\n",
        "\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])\n",
        "print(len(test_inputs))\n",
        "print(len(test_labels))\n",
        "print(len(test_masks))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([    2,  7016,  4600,  3488, 18168, 18168, 21245,   351,  3349,   228,\n",
            "         3349,  2315,   515,  4384,   826,  1040,  1557,     3,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n",
            "150000\n",
            "150000\n",
            "150000\n",
            "tensor([    2,  7016,  4600,  3488, 18168, 18168, 21245,   351,  3349,   228,\n",
            "         3349,  2315,   515,  4384,   826,  1040,  1557,     3,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n",
            "150000\n",
            "150000\n",
            "150000\n",
            "tensor([    2,  6956,   228, 10494,    83,     3,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n",
            "50000\n",
            "50000\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8sZgSSrUN0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 16\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fUlXExfUSfG",
        "colab_type": "text"
      },
      "source": [
        "# 디바이스 설정 및 모델 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY7v4ITpUUq0",
        "colab_type": "code",
        "outputId": "c9b9d538-c1d5-4a43-8a68-7061cbda4641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HfMdWXTUYFo",
        "colab_type": "code",
        "outputId": "7f973257-2a66-4941-f1a8-c1dd45ed6077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcV7G72_UZln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "# 미리 학습된 한국어 BERT 모델을 사용함.\n",
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/My Drive/bert_pytorch/001_bert_morp_pytorch/\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7CxSP0LUbNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 2\n",
        "epoch=0\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmsR2Ib1Ux9N",
        "colab_type": "text"
      },
      "source": [
        "# 학습 시작\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRUfrFoYUz8i",
        "colab_type": "code",
        "outputId": "2fac7cca-9b85-4680-b984-7060e8fa9385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#랜덤 시드 설정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    #학습 시작\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, 2))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "            print(total_loss/step)\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.12f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "    #매 에포크 마다 결과값 저장\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler' : scheduler.state_dict()\n",
        "        }, \"/content/drive/My Drive/kor_bert_senti\"+\"%d\"%(epoch_i))\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  9,375.    Elapsed: 0:03:56.\n",
            "0.42218369123339655\n",
            "  Batch 1,000  of  9,375.    Elapsed: 0:07:51.\n",
            "0.3885974925868213\n",
            "  Batch 1,500  of  9,375.    Elapsed: 0:11:46.\n",
            "0.36613654176642496\n",
            "  Batch 2,000  of  9,375.    Elapsed: 0:15:41.\n",
            "0.3543316984605044\n",
            "  Batch 2,500  of  9,375.    Elapsed: 0:19:36.\n",
            "0.3453534990131855\n",
            "  Batch 3,000  of  9,375.    Elapsed: 0:23:32.\n",
            "0.33892503745357194\n",
            "  Batch 3,500  of  9,375.    Elapsed: 0:27:28.\n",
            "0.33290335967817475\n",
            "  Batch 4,000  of  9,375.    Elapsed: 0:31:25.\n",
            "0.3285522306282073\n",
            "  Batch 4,500  of  9,375.    Elapsed: 0:35:21.\n",
            "0.32392874596226545\n",
            "  Batch 5,000  of  9,375.    Elapsed: 0:39:18.\n",
            "0.3193317886274308\n",
            "  Batch 5,500  of  9,375.    Elapsed: 0:43:14.\n",
            "0.3164164243370972\n",
            "  Batch 6,000  of  9,375.    Elapsed: 0:47:11.\n",
            "0.3125434384603674\n",
            "  Batch 6,500  of  9,375.    Elapsed: 0:51:08.\n",
            "0.30932538038750107\n",
            "  Batch 7,000  of  9,375.    Elapsed: 0:55:05.\n",
            "0.30595358233393305\n",
            "  Batch 7,500  of  9,375.    Elapsed: 0:59:02.\n",
            "0.3037877607258658\n",
            "  Batch 8,000  of  9,375.    Elapsed: 1:02:58.\n",
            "0.30252206026320344\n",
            "  Batch 8,500  of  9,375.    Elapsed: 1:06:56.\n",
            "0.30043284367616563\n",
            "  Batch 9,000  of  9,375.    Elapsed: 1:10:53.\n",
            "0.29852666196537514\n",
            "\n",
            "  Average training loss: 0.297153640801\n",
            "  Training epcoh took: 1:13:50\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  9,375.    Elapsed: 0:03:57.\n",
            "0.1984204819649458\n",
            "  Batch 1,000  of  9,375.    Elapsed: 0:07:53.\n",
            "0.19956075501069426\n",
            "  Batch 1,500  of  9,375.    Elapsed: 0:11:50.\n",
            "0.19747626379753153\n",
            "  Batch 2,000  of  9,375.    Elapsed: 0:15:47.\n",
            "0.19976027482748032\n",
            "  Batch 2,500  of  9,375.    Elapsed: 0:19:43.\n",
            "0.19928124709278344\n",
            "  Batch 3,000  of  9,375.    Elapsed: 0:23:40.\n",
            "0.1997223509121686\n",
            "  Batch 3,500  of  9,375.    Elapsed: 0:27:37.\n",
            "0.19950877907712544\n",
            "  Batch 4,000  of  9,375.    Elapsed: 0:31:34.\n",
            "0.20035940156783907\n",
            "  Batch 4,500  of  9,375.    Elapsed: 0:35:30.\n",
            "0.19940204621147778\n",
            "  Batch 5,000  of  9,375.    Elapsed: 0:39:27.\n",
            "0.19915595158375798\n",
            "  Batch 5,500  of  9,375.    Elapsed: 0:43:23.\n",
            "0.1991180447363718\n",
            "  Batch 6,000  of  9,375.    Elapsed: 0:47:20.\n",
            "0.19852368316520005\n",
            "  Batch 6,500  of  9,375.    Elapsed: 0:51:17.\n",
            "0.1985614738358328\n",
            "  Batch 7,000  of  9,375.    Elapsed: 0:55:13.\n",
            "0.19830277063830623\n",
            "  Batch 7,500  of  9,375.    Elapsed: 0:59:09.\n",
            "0.19813875151971977\n",
            "  Batch 8,000  of  9,375.    Elapsed: 1:03:05.\n",
            "0.19786523700365796\n",
            "  Batch 8,500  of  9,375.    Elapsed: 1:07:01.\n",
            "0.1975181769156719\n",
            "  Batch 9,000  of  9,375.    Elapsed: 1:10:57.\n",
            "0.1969976985640824\n",
            "\n",
            "  Average training loss: 0.196237413053\n",
            "  Training epcoh took: 1:13:54\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOhrVUgolE1U",
        "colab_type": "code",
        "outputId": "ef3f3615-7bcf-4404-a829-b23cdfeee64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "print(\"\")\n",
        "print(\"Running Validation...\")\n",
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for batch in test_dataloader:\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:07:22\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
